
import json
from typing import Dict, Optional
from pathlib import Path

def generate_fields(dirname: Optional[str] = None) -> None :
    """
    Generate tab-separated table of model fields

    :param dirname: path to mxlims working directory
    :return:
    """
    if dirname:
        mxlims_dir = Path(dirname)
    else:
        mxlims_dir = Path.cwd()

    schema_dir = mxlims_dir / "mxlims" / "schemas"

    # Read all relevant schemas
    schemadata = {}
    for tag in ("data", "datatypes", "objects"):
        dd1 = schemadata[tag] = {}
        for fpath in (schema_dir / tag).iterdir():
            name = fpath.stem
            with fpath.open(encoding="utf-8") as fp0:
                dd1[name] = json.load(fp0)

    # Create Datatype dictionaries
    datatypes = {}
    for tag, dd1 in sorted(schemadata["datatypes"].items()):
        props = dd1.get("properties")
        if props:
            datatypes[tag] = dd2 = {}
            for name, dd3 in props.items():
                dd2[name] = get_type_desc(dd3, schemadata["datatypes"])

    # Create Data dictionaries
    data = {}
    for tag, dd1 in sorted(schemadata["data"].items()):
        props = dd1.get("properties")
        if props:
            data[tag] = dd2 = {
                "annotation": {
                    "type": "str",
                    "description": "Comment or annotation",
                    "basetype": "str",
                },
            }
            for name, dd3 in props.items():
                dd2[name] = get_type_desc(dd3, schemadata["datatypes"])

    typemap = {}
    fieldmap = {}
    import_types = set()
    for tag, dd1 in sorted(schemadata["objects"].items()):
        ll1 = dd1.get("allOf", ())
        # annotation is special-cased as the only non-implementation field in MxlimsObject
        if len(ll1) > 1:
            for dd2 in reversed(ll1):
                # Superclass first
                txt = dd2["$ref"]
                txt = txt.split("/")[-1]
                typ = txt.split(".")[0]
                dd3 = data.get(typ, {})
                for tag2, dd4 in dd3.items():
                    fulltag1 = ".".join((tag, tag2))
                    typ2 = dd4.get("type", "NOTYPE")
                    desc = dd4.get("description", "-")
                    datatype = datatypes.get(typ2)
                    typemap[fulltag1] = typ2
                    if datatype:
                        import_types.add(typ2)
                        for tag3, prop in datatype.items():
                            fulltag2 = ".".join((fulltag1, tag3))
                            typ3 = prop.get("type", "NOTYPE")
                            desc = prop.get("description", "-")
                            typemap[fulltag2] = typ3
                            fieldmap[fulltag2] = (typ3, desc)
                    else:
                        for name in dd4["basetype"].split("|"):
                            if name in datatypes:
                                import_types.add(name)
                        fieldmap[fulltag1] = (typ2, desc)

    outfile = mxlims_dir / "mxlims" / "impl" / "fieldmap.tsv"
    with open(outfile, "w", encoding="utf-8") as fp:
        fp.write("Field\tType\tDescription\n")
        fp.write(
            ",\n".join(
                "\t".join((item[0], item[1][0], item[1][1]))
                for item in sorted(fieldmap.items())
            )
        )
    outfile = mxlims_dir / "mxlims" / "impl" / "typemap.py"
    with open(outfile, "w", encoding="utf-8") as fp:
        fp.write("""# Map of MXLIMS concatenated field strings to type
# Generated by mxlims.impl.generate_fields
#
# Concatenated field strings, and hence this mapping, are used in setting up simple
# mappings used in conversion to other formats.
#
# NOTE Not all parts of the MXLIMS model can be reached with a concatenated field string
# Types that are lists or unions of Datatypes contain further attributes but
# cannot be mapped in this way. Examples are
# MacromoleculeSample.components (type: List[SampleComponent])
# or DropRegion.region (type: Union[ImageRegion,PlateRegion])
# Conversion access to these fields require more complex code than the simple
# mapping table look-up
#
# Concatenated field strings can be used to address dictionaries. E.g.
# Macromolecule.identifiers.SwissProt maps to Macromolecule.identifiers["SwissProt"]

from typing import Any, Dict, List

""")
        fp.writelines(
            "from mxlims.pydantic.datatypes.{name} import {name}\n".format(name=name)
            for name in sorted(import_types)
        )
        fp.write("\ntypemap = {\n")
        fp.writelines('    "%s": %s,\n' % item for item in sorted(typemap.items()))
        fp.write("}\n")


def get_type_desc(adict: dict, datatypes: dict) -> Dict[str, str]:
    type_remap = {
        "integer": "int",
        "number": "float",
        "boolean": "bool",
        "string": "str",
        "array": "List"
    }

    basetype = None
    desc = adict.get("description", "NONE")
    if "allOf" in adict:
        # assert len(dict["allOf"]) == 1
        txt = adict["allOf"][0]["$ref"]
        txt = txt.split("/")[-1]
        typ = txt.split(".")[0]
        dtt = datatypes.get(typ)
        if dtt:
            typ2 = dtt.get("type")
            if typ2 != "object":
                typ = type_remap.get(typ2, typ2)
    elif "oneOf" in adict:
        typs = []
        for dd1 in adict["oneOf"]:
            txt = dd1["$ref"]
            txt = txt.split("/")[-1]
            typ0 = txt.split(".")[0]
            typs.append(type_remap.get(typ0, typ0))
        typ = "|".join(typs)
    else:
        typ = adict.get("type")
        if typ == "array":
            items = adict.get("items")
            if items:
                typ2 = items.get("type")
                typ2 = type_remap.get(typ2, typ2)
                basetype = typ2
                if not typ2:
                    typ2 = items["$ref"].split("/")[-1].split(".")[0]
                    typ2 = type_remap.get(typ2, typ2)
                    basetype = typ2
                elif typ2 == "List":
                    typ3 = items["items"].get("type")
                    typ3 = type_remap.get(typ3, typ3)
                    typ2 = f"List[{typ3}]"
                    basetype = typ3
                else:
                    dtt = datatypes.get(typ2)
                    if dtt:
                        typ2 = dtt.get("type")
                        typ2 = type_remap.get(typ2, typ2)
                        basetype = typ2

            else:
                typs = []
                for item in adict["prefixItems"]:
                    typ0 = item["type"]
                    typs.append(type_remap.get(typ0, typ0))
                typ2 = "|".join(typs)
                basetype = typ2
            typ = f"List[{typ2}]"
        elif typ == "object":
            # Dictionary object
            addp = adict.get("additionalProperties")
            typ3 = "Any"
            if addp:
                typ2 = addp.get("type")
                if typ2:
                    dtt = datatypes.get(typ2)
                    if dtt:
                        typ2 = dtt.get("type", typ2)
                    if typ2 in type_remap:
                        typ3 = type_remap[typ2]
            typ = f"Dict[str, {typ3}]"
        elif not typ:
            txt = adict.get("$ref")
            if txt:
                txt = txt.split("/")[-1]
                typ = txt.split(".")[0]
                dtt = datatypes.get(typ)
                if dtt:
                    typ = dtt.get("type")
        typ = type_remap.get(typ, typ)
    return  {
        "type": typ,
        "description": desc,
        "basetype": basetype or typ,
    }


if __name__ == "__main__":

    from argparse import ArgumentParser, RawTextHelpFormatter

    parser = ArgumentParser(
        prog="generate_field_list.py",
        formatter_class=RawTextHelpFormatter,
        prefix_chars="--",
        description="""
MXLIMS code generation helper. Assumes standard directory structure""",
    )

    parser.add_argument(
        "--dirname",
        metavar="dirname",
        default=None,
        help="Path to directory containing mxlims/ and docs/ subdirectory\n",
    )

    argsobj = parser.parse_args()
    options_dict = vars(argsobj)

    field_data = generate_fields(**options_dict)